{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-2LR05TRMR3"
   },
   "source": [
    "### Ageing_Sign_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "330v306IIMdh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # for image augmentation\n",
    "from tensorflow.keras.optimizers import Adam # optimizer\n",
    "from tensorflow.keras.preprocessing.image import img_to_array # converting image to array\n",
    "from tensorflow.keras.models import Sequential # forward flowing network\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Flatten, Dropout, Conv2D # dense-fully connected nodes,dropout-# of nodes to block\n",
    "from tensorflow.keras.applications import EfficientNetB0 #efficientNet model B0 (img size 244, 244, 3)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # for multilabel classification\n",
    "from sklearn.model_selection import train_test_split # splitting the data into training and testing\n",
    "import matplotlib.pyplot as plt # for plotting training & accuracy graph \n",
    "from imutils import paths # to work on directories\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm1v5Tja-Guc"
   },
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VZwLGmB-ZxC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrPZ3PPFIOZ7"
   },
   "outputs": [],
   "source": [
    "#Defining Constants\n",
    "EPOCHS = 20 # no. of iterations the neural model trains\n",
    "INIT_LR = 1e-3 # default value of Adam optimizer(0.001)\n",
    "BS = 25 # batch_size\n",
    "IMAGE_DIMS = (244, 244, 3) # Image dimensions for EfficientNetB0\n",
    "tf.compat.v1.disable_eager_execution() # synchronization(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDFamng1Id2b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-eRKSd_Ilhn"
   },
   "outputs": [],
   "source": [
    "###########################################PATH TO dataset FOLDER COMES HERE####\n",
    "imagePaths = sorted(list(paths.list_images(\"/content/gdrive/My Drive/dataset/\")))# gathering all image paths\n",
    "random.seed(42) # specifying a random no. to randomize the directories\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywUcqyYBQmVr"
   },
   "outputs": [],
   "source": [
    "for imagePath in imagePaths: #for every directory we're traversing all the images\n",
    "  image = cv2.imread(imagePath) # reading the image\n",
    "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0])) # resizing the image to match efficientNetB0 conditions\n",
    "  image = img_to_array(image) # converting the resized image to array\n",
    "  data.append(image)\n",
    "\n",
    "  l = label = imagePath.split(os.path.sep)[-2].split(\"_\") # splitting the list of labels from the directory name\n",
    "  labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9-uTSVua_EJ"
   },
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\")/255.0 # preprocessing(normalization) the image to get values between 0 and 1 to ease computation burden\n",
    "labels = np.array(labels, dtype=object) # converting the label to an array\n",
    "print(\"[INFO] data matrix: {} images ({:.2f} MB)\".format(len(imagePaths), data.nbytes / (1024 * 1000.0))) # gathering info about the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kf-pyG-8e1Tr"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] class labels: \")\n",
    "mlb = MultiLabelBinarizer() # initializing the MultiLabelBinarizer class\n",
    "labels = mlb.fit_transform(labels) # this class converts all the labels into distinct values\n",
    "\n",
    "for (i, label) in enumerate(mlb.classes_): # printing the labels (total 4)\n",
    "    print(\"{}. {}\".format(i+1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sa9iTBY3e9T5"
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42) # splitting data into training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFm7Mxe7gEDL"
   },
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVbCFRwsgN3H"
   },
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbEDp4bMgRcI"
   },
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fIId7qygSXI"
   },
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zDaS0RPgTKo"
   },
   "outputs": [],
   "source": [
    "dataGen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ") # creating modified images, by rotating, shifting, zooming, shearing or flipping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeMv4Lv0gyEq"
   },
   "outputs": [],
   "source": [
    "dataGen.fit(trainX) # applying the augmentation the training images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MibUtXXLhLne"
   },
   "outputs": [],
   "source": [
    "#Specifying the architecture of our neural network\n",
    "conv_base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMAGE_DIMS)#input layer\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(mlb.classes_), activation=\"sigmoid\"))# output layer sigmoid is more effective for multilabel classification\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXGG_139hTfY"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPwhw3hMiySj"
   },
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) # binary_crossentropy is a loss function for multi label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twWnXlnOi-AT"
   },
   "outputs": [],
   "source": [
    "#training the model\n",
    "print(\"[INFO] training the network...\")\n",
    "H=model.fit(\n",
    "    dataGen.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwI1h_Go1qBT"
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 30\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "############PATH WHERE YOU WANT TO SAVE THE graph FILE COMES HERE##\n",
    "plt.savefig(\"/content/gdrive/My Drive/model_weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIWxqLDJjfaU"
   },
   "outputs": [],
   "source": [
    "#saving the model and weights\n",
    "model_json = model.to_json()\n",
    "##########PATH WHERE YOU WHAT TO SAVE THE model.json FILE COMES HERE########\n",
    "with open(\"path_to_folder_where_you_want_to_save_the_model\"+\"model.json\", \"w\") as file:\n",
    "  file.write(model_json)\n",
    "  file.close()\n",
    "###################PATH WHERE YOU WANT TO SAVE THE weights.h5 FILE COMES HERE##\n",
    "model.save_weights(\"path_to_folder_where_you_want_to_save_the_weights\"+\"weights.h5\")\n",
    "print(\"Model Saved Successfully!!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMR7EL9KtTwmlKSsTm3zuS3",
   "collapsed_sections": [],
   "name": "Ageing_Sign_Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
